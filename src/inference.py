import h5py
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Tuple
import torch

# Import your preprocessor functions and model loader.
# Ensure these are in your PYTHONPATH or same directory as appropriate.
from .preprocessor import load_data, rescale_and_format, tokenize_sequence, decode_sequence
from .models.qwen import load_qwen  # assume you have a module named model_loader with load_qwen defined

# Constants for LLMTIME preprocessing
SCALE_PERCENTILE_ALPHA = 0.95
DECIMAL_PLACES = 2


def generate_forecast(
        preprocessed_text: str,
        instruction: str,
        model, tokenizer,
        max_new_tokens: int = 512,
        use_chat_template: bool = False
        ) -> str:

    """
    Generates forecast text from a preprocessed time series string by using the Qwen2.5-Instruct model.

    Parameters:
        preprocessed_text (str): Preprocessed time series text.
        instruction (str): Instruction appended to the prompt.
        model: The loaded Qwen model.
        tokenizer: The loaded tokenizer.
        max_new_tokens (int): Maximum number of tokens to generate.

    Returns:
        str: The forecast text generated by the model.
    """

    # Construct prompt by combining preprocessed text and instruction.
    prompt = preprocessed_text + " " + instruction



    # Optionally, use a chat template for better context.
    messages = [
        {"role": "system", "content": "You are a helpful assistant forecasting time series."},
        {"role": "user", "content": prompt}
    ]
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )

    # Tokenize the prompt.
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

    # Generate predictions.
    generated_ids = model.generate(
        **model_inputs,
        max_new_tokens=max_new_tokens
    )

    # Remove the prompt tokens.
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]

    # Decode generated tokens to text.
    forecast_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return forecast_text


def visualize_forecast(
        original_sequence: np.ndarray,
        forecast_sequence: np.ndarray,
        input_ratio: float,
        metric: str = "MAE") -> None:
    """
    Visualizes the original and forecast trajectories and computes a basic error metric.

    Parameters:
        original_sequence (np.ndarray): The full original time series (T, features).
        forecast_sequence (np.ndarray): The forecasted time series (T_pred, features).
        input_ratio (float): The ratio of the original sequence used as input.
        metric (str): The error metric to compute ("MAE" or "MSE"). Defaults to "MAE".
    """
    # Determine the cutoff point.
    total_time_steps = original_sequence.shape[0]
    input_steps = int(total_time_steps * input_ratio)

    # Create a time axis assuming equal spacing.
    time_axis = np.linspace(0, 1, total_time_steps)
    forecast_time_axis = np.linspace(time_axis[input_steps], 1, forecast_sequence.shape[0])

    # For visualization, we plot the first feature (e.g., prey) and the second (e.g., predator) separately.
    fig, axs = plt.subplots(2, 1, figsize=(10, 8))
    features = ["Prey", "Predator"]
    errors = []
    for i in range(original_sequence.shape[1]):
        axs[i].plot(time_axis, original_sequence[:, i], label="Original")
        axs[i].plot(forecast_time_axis, forecast_sequence[:, i], label="Forecast", linestyle="--")
        axs[i].set_title(features[i])
        axs[i].set_xlabel("Normalized Time")
        axs[i].set_ylabel("Population")
        axs[i].legend()

        # Compute error metric on the overlapping forecast portion if lengths match.
        if forecast_sequence.shape[0] <= (total_time_steps - input_steps):
            original_future = original_sequence[input_steps:input_steps + forecast_sequence.shape[0], i]
        else:
            original_future = original_sequence[input_steps:, i]
        if metric.upper() == "MAE":
            error = np.mean(np.abs(original_future - forecast_sequence[:len(original_future), i]))
        elif metric.upper() == "MSE":
            error = np.mean((original_future - forecast_sequence[:len(original_future), i])**2)
        else:
            error = None
        errors.append(error)

    plt.tight_layout()
    plt.show()

    # Print the error metrics.
    for i, err in enumerate(errors):
        print(f"{features[i]} {metric}: {err:.4f}")
